{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Building Energy Anomaly Detection - Final Report\n",
                "\n",
                "## 1. Executive Summary\n",
                "This report consolidates the findings from the analysis of the Building Data Genome 2 (BDG2) dataset. We implemented an end-to-end Machine Learning pipeline to detect energy anomalies in commercial buildings. \n",
                "\n",
                "**Key Findings:**\n",
                "- **Objective**: Detect and quantify abnormal energy consumption patterns.\n",
                "- **Method**: Ensemble of Isolation Forest, LOF, and Elliptic Envelope.\n",
                "- **Impact**: Identification of potential energy waste events to drive cost savings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import sys\n",
                "import os\n",
                "\n",
                "# Setup path\n",
                "current_dir = os.getcwd()\n",
                "project_root = os.path.dirname(current_dir)\n",
                "if project_root not in sys.path:\n",
                "    sys.path.append(project_root)\n",
                "\n",
                "from src.data_loader import load_data\n",
                "from src.preprocessing import preprocess_data\n",
                "from src.features import engineer_features\n",
                "from src.models import train_anomaly_models\n",
                "\n",
                "# Visual settings\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "sns.set_palette('muted')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Pipeline Execution\n",
                "Loading data, cleaning, generating features, and running the anomaly detection models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Load Data (Limit to 100 buildings for performance in this report)\n",
                "print(\"Loading data...\")\n",
                "data_path = os.path.join(project_root, 'data')\n",
                "df_raw = load_data(data_path, building_limit=100)\n",
                "\n",
                "# 2. Preprocess\n",
                "print(\"Preprocessing...\")\n",
                "df_clean = preprocess_data(df_raw)\n",
                "\n",
                "# 3. Feature Engineering\n",
                "print(\"Engineering features...\")\n",
                "df = engineer_features(df_clean)\n",
                "\n",
                "# 4. Modeling\n",
                "features = ['electricity', 'chilled_water', 'steam', 'temperature', 'humidity', \n",
                "            'electricity_rolling_mean', 'electricity_deviation', 'hour', 'day_of_week']\n",
                "model_features = [c for c in features if c in df.columns]\n",
                "X = df[model_features].fillna(0)\n",
                "\n",
                "print(\"Training models...\")\n",
                "output = train_anomaly_models(X)\n",
                "results = output['results']\n",
                "df_final = pd.concat([df, results], axis=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Anomaly Analysis\n",
                "Visualizing the detected anomalies to understand their distribution and characteristics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate Anomaly Rate\n",
                "n_anomalies = df_final['is_anomaly'].sum()\n",
                "total_points = len(df_final)\n",
                "rate = (n_anomalies / total_points) * 100\n",
                "print(f\"Total Data Points: {total_points:,}\")\n",
                "print(f\"Detected Anomalies: {n_anomalies:,} ({rate:.2f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization: Anomalies over Time (First 2000 hours)\n",
                "plt.figure(figsize=(15, 6))\n",
                "subset = df_final.iloc[:2000]\n",
                "plt.plot(subset['timestamp'], subset['electricity'], label='Normal Consumption', alpha=0.6, color='tab:blue')\n",
                "anomalies = subset[subset['is_anomaly'] == 1]\n",
                "plt.scatter(anomalies['timestamp'], anomalies['electricity'], color='red', label='Anomaly', s=30, zorder=5)\n",
                "plt.title('Electricity Consumption & Detected Anomalies (Sample Window)', fontsize=14)\n",
                "plt.xlabel('Date')\n",
                "plt.ylabel('Normalized Consumption')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Temporal Patterns\n",
                "When do anomalies happen most frequently?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Anomalies by Hour of Day\n",
                "anomaly_df = df_final[df_final['is_anomaly'] == 1]\n",
                "hourly_counts = anomaly_df['hour'].value_counts().sort_index()\n",
                "\n",
                "plt.figure(figsize=(12, 5))\n",
                "sns.barplot(x=hourly_counts.index, y=hourly_counts.values, color='salmon')\n",
                "plt.title('Frequency of Anomalies by Hour of Day', fontsize=14)\n",
                "plt.xlabel('Hour (0-23)')\n",
                "plt.ylabel('Number of Anomalies')\n",
                "plt.xticks(range(0, 24))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Anomalies by Day of Week\n",
                "day_counts = anomaly_df['day_of_week'].value_counts().sort_index()\n",
                "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
                "\n",
                "plt.figure(figsize=(10, 5))\n",
                "sns.barplot(x=[days[i] for i in day_counts.index], y=day_counts.values, color='skyblue')\n",
                "plt.title('Frequency of Anomalies by Day of Week', fontsize=14)\n",
                "plt.ylabel('Number of Anomalies')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Business Impact & Cost Analysis\n",
                "Quantifying the financial impact of the detected anomalies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cost Estimation Assumptions\n",
                "avg_kwh_cost = 0.12 # $0.12 per kWh\n",
                "\n",
                "# Note: Our data is normalized [0,1], so for real cost we would need to inverse transform.\n",
                "# Valid conceptual estimation assuming the column represents relative magnitude.\n",
                "# For this report, we'll calculate the 'Units' of anomalous energy.\n",
                "\n",
                "total_energy = df_final['electricity'].sum()\n",
                "anomalous_energy = anomaly_df['electricity'].sum()\n",
                "percent_waste = (anomalous_energy / total_energy) * 100\n",
                "\n",
                "# Hypothetical Cost (if sum was kWh)\n",
                "estimated_waste_cost = anomalous_energy * avg_kwh_cost\n",
                "\n",
                "print(f\"Total Energy Units Processed: {total_energy:,.0f}\")\n",
                "print(f\"Total Anomalous Energy Units: {anomalous_energy:,.0f}\")\n",
                "print(f\"Potential Waste: {percent_waste:.1f}% of total consumption\")\n",
                "print(f\"\\nESTIMATED FINANCIAL IMPACT (Normalized Units): ${estimated_waste_cost:,.2f}\")\n",
                "print(\"(Note: Real dollar value requires inverse-scaling to original kWh values)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Recommendations\n",
                "\n",
                "Based on the analysis:\n",
                "1.  **Investigate Peak Hours**: Focus maintenance teams on the hours identified in the \"Anomalies by Hour\" chart (often transition periods like 6-8 AM or 6-8 PM).\n",
                "2.  **Weekend Audits**: If weekend anomalies are high, check for equipment failing to shut down (HVAC setbacks).\n",
                "3.  **Automated Alerts**: Deploy this model to flag anomalies in real-time, allowing facility managers to intervene before costs accumulate.\n",
                "4.  **Hardware Check**: For buildings with persistent anomalies, physically inspect sensors and major equipment (chillers, boilers)."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}