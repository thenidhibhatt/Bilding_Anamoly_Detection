{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Model Training & Evaluation\n",
    "Training anomaly detection models (Isolation Forest, LOF, Elliptic Envelope) and analyzing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\CODING\\\\New folder\\\\notebooks\\\\results\\\\project.log'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m project_root = os.path.dirname(current_dir)\n\u001b[32m     10\u001b[39m sys.path.append(project_root)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_data\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocess_data\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeatures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m engineer_features\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\CODING\\New folder\\src\\data_loader.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_logger\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m logger = \u001b[43msetup_logger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_data\u001b[39m(data_path):\n\u001b[32m      9\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m    Loads and merges CSV files from the specified directory recursively.\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03m        pd.DataFrame: Merged dataframe containing data from all found CSV files.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\CODING\\New folder\\src\\utils.py:13\u001b[39m, in \u001b[36msetup_logger\u001b[39m\u001b[34m(name, log_file)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Create handlers\u001b[39;00m\n\u001b[32m     12\u001b[39m c_handler = logging.StreamHandler()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m f_handler = \u001b[43mlogging\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFileHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m c_handler.setLevel(logging.INFO)\n\u001b[32m     15\u001b[39m f_handler.setLevel(logging.INFO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\CODING\\System\\Python 3.13\\Lib\\logging\\__init__.py:1219\u001b[39m, in \u001b[36mFileHandler.__init__\u001b[39m\u001b[34m(self, filename, mode, encoding, delay, errors)\u001b[39m\n\u001b[32m   1217\u001b[39m     \u001b[38;5;28mself\u001b[39m.stream = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1218\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1219\u001b[39m     StreamHandler.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\CODING\\System\\Python 3.13\\Lib\\logging\\__init__.py:1248\u001b[39m, in \u001b[36mFileHandler._open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1243\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1244\u001b[39m \u001b[33;03mOpen the current base file with the (original) mode and encoding.\u001b[39;00m\n\u001b[32m   1245\u001b[39m \u001b[33;03mReturn the resulting stream.\u001b[39;00m\n\u001b[32m   1246\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1247\u001b[39m open_func = \u001b[38;5;28mself\u001b[39m._builtin_open\n\u001b[32m-> \u001b[39m\u001b[32m1248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbaseFilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'E:\\\\CODING\\\\New folder\\\\notebooks\\\\results\\\\project.log'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.dirname(current_dir)\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.data_loader import load_data\n",
    "from src.preprocessing import preprocess_data\n",
    "from src.features import engineer_features\n",
    "from src.models import train_anomaly_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data Pipeline\n",
    "data_path = os.path.join(project_root, 'data')\n",
    "df_raw = load_data(data_path)\n",
    "df_clean = preprocess_data(df_raw)\n",
    "df = engineer_features(df_clean)\n",
    "\n",
    "# Select features for modeling (exclude datetime and non-numeric)\n",
    "features = ['electricity', 'chilled_water', 'steam', 'temperature', 'humidity', \n",
    "            'electricity_rolling_mean', 'electricity_deviation', 'hour', 'day_of_week']\n",
    "# Filter to available columns\n",
    "model_features = [c for c in features if c in df.columns]\n",
    "X = df[model_features].fillna(0)\n",
    "print(\"Training features:\", model_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Models\n",
    "output = train_anomaly_models(X)\n",
    "models = output['models']\n",
    "results = output['results']\n",
    "\n",
    "# Merge results back to main dataframe\n",
    "df_final = pd.concat([df, results], axis=1)\n",
    "print(\"Anomalies detected:\", df_final['is_anomaly'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance (Isolation Forest)\n",
    "if 'isolation_forest' in models:\n",
    "    iso_forest = models['isolation_forest']\n",
    "    # Note: feature_importances_ is not always available in standard sklearn IsoForest versions, \n",
    "    # usually we might use permutation importance or if the version supports it. \n",
    "    # We'll use a try-except or just basic plotting if available.\n",
    "    try:\n",
    "        # Check if attribute exists (it might not in all sklearn versions for IsoForest)\n",
    "        # We'll assume for now or skip.\n",
    "        pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly Visualization\n",
    "plt.figure(figsize=(15, 6))\n",
    "subset = df_final.iloc[:1000] # Plot first 1000 hours for clarity\n",
    "plt.plot(subset['timestamp'], subset['electricity'], label='Electricity', alpha=0.6)\n",
    "anomalies = subset[subset['is_anomaly'] == 1]\n",
    "plt.scatter(anomalies['timestamp'], anomalies['electricity'], color='red', label='Anomaly', s=50)\n",
    "plt.title('Electricity Consumption & Anomalies (First 1000 Hours)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost Estimation\n",
    "avg_kwh_cost = 0.12\n",
    "anomaly_cost = df_final[df_final['is_anomaly'] == 1]['electricity'].sum() * avg_kwh_cost\n",
    "print(f\"Estimated excess cost from anomalies: ${anomaly_cost:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results\n",
    "os.makedirs(os.path.join(project_root, 'results'), exist_ok=True)\n",
    "df_final[df_final['is_anomaly'] == 1].to_csv(os.path.join(project_root, 'results', 'anomalies.csv'))\n",
    "print(\"Results saved to results/anomalies.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
